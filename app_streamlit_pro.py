#!/usr/bin/env python
# -*- coding: utf-8 -*-

# ============================================================
# í¸ì˜ì  ìˆ˜ìš”ì˜ˆì¸¡ & ë°œì£¼ ì¶”ì²œ â€” Pro Suite (íŒ¨ì¹˜ ë²„ì „, ë©€í‹° CSV + ì›”ë³„ ê·¸ë˜í”„)
#  - â‘  ì—¬ëŸ¬ CSV ì—…ë¡œë“œ/ì„ íƒ â†’ ìë™ ê²°í•©(ì˜µì…˜: source ì—´ ì¶”ê°€)
#  - â‘¡ ì»¬ëŸ¼ ë§¤í•‘: "ì»¬ëŸ¼ëª…"ì´ ì•„ë‹ˆë¼ "ì˜ˆì‹œ ê°’" ê¸°ë°˜ ì„ íƒ
#  - â‘¢ ì˜ˆì¸¡Â·ë°œì£¼: ì¬ê³  ì»¬ëŸ¼ ìë™ ì¸ì‹ â†’ ì˜ˆì¸¡ ê¸°ê°„/ë°œì£¼ëŸ‰ ìë™ ê³„ì‚°
#       Â· ë¦¬ë“œíƒ€ì„ / ì„œë¹„ìŠ¤ë ˆë²¨ / ì•ˆì „ì¬ê³  / MOQ / íŒ©ë‹¨ìœ„ ì…ë ¥ ì œê±°
#  - â‘£ ë¶„ì„(ê·¸ë˜í”„):
#       Â· ìš°ì‚°: ì›”ë³„ ê°•ìˆ˜ëŸ‰ â†” ìš°ì‚° íŒë§¤ëŸ‰ (ì‚°ì ë„ + íšŒê·€ì„  + ì¼ë³„ ì„ í˜• ê·¸ë˜í”„)
#       Â· êµ°ê³ êµ¬ë§ˆ: ì›”ë³„ ê¸°ì˜¨ â†” êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰ (ì‚°ì ë„ + íšŒê·€ì„  + ì¼ë³„ ì„ í˜• ê·¸ë˜í”„)
#       Â· ì „ì²´: ìš°ì‚°Â·êµ°ê³ êµ¬ë§ˆ ì œì™¸ ì „ì²´ ìƒí’ˆ ì¼ë³„ íŒë§¤ëŸ‰ ì„ í˜• ê·¸ë˜í”„
#  - ì‚¬ì´ë“œë°”: ì‹¤í–‰ íŒŒì¼ í‘œì‹œ + ìºì‹œ ì´ˆê¸°í™”
# ============================================================

import os, io, pickle, time, subprocess, sys
from datetime import timedelta
from pathlib import Path

import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

from utils_io import read_csv_flexible, save_utf8sig, ensure_dirs, auto_map_columns
from preprocess import make_matrix
from train_core import train_and_score, save_artifacts

# Altair ëŒ€ìš©ëŸ‰ ë Œë”ë§ ì•ˆì „ì¥ì¹˜ (í–‰ ìˆ˜ ì œí•œ í•´ì œ)
alt.data_transformers.disable_max_rows()

# ------------------------------------------------------------
# í˜ì´ì§€/ì‚¬ì´ë“œë°”
# ------------------------------------------------------------
st.set_page_config(page_title="í¸ì˜ì  ìˆ˜ìš”ì˜ˆì¸¡ & ë°œì£¼ ì¶”ì²œ â€” Pro Suite (íŒ¨ì¹˜)", layout="wide")

# __file__ ì´ ì—†ëŠ” Colab ê°™ì€ í™˜ê²½ ë°©ì–´ìš©
try:
    script_name = Path(__file__).resolve().name
except NameError:
    script_name = "app_streamlit_pro.py"

st.sidebar.write("ğŸ§­ ì‹¤í–‰ íŒŒì¼:", script_name)
if st.sidebar.button("ìºì‹œ ì´ˆê¸°í™” í›„ ë‹¤ì‹œ ì‹¤í–‰"):
    try:
        st.cache_data.clear()
    except Exception:
        pass
    try:
        st.cache_resource.clear()
    except Exception:
        pass
    st.experimental_rerun()

# ------------------------------------------------------------
# ê¸°ë³¸ í™˜ê²½/ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------------
PROJ = os.getcwd()                         # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬(ì•± ë£¨íŠ¸)
DATA_DIR   = os.path.join(PROJ, "data")    # CSV ë°ì´í„° í´ë”
ARTI_DIR   = os.path.join(PROJ, "artifacts")  # í•™ìŠµ ì¤‘ê°„ì‚°ì¶œë¬¼(ë¡œê·¸/ì„±ëŠ¥ ë“±) ë³´ê´€
MODELS_DIR = os.path.join(PROJ, "models")     # í•™ìŠµëœ ëª¨ë¸ pkl ë³´ê´€
ensure_dirs(DATA_DIR, ARTI_DIR, MODELS_DIR)   # í´ë” ì—†ìœ¼ë©´ ìƒì„±

# ------------------------------------------------------------
# ìœ í‹¸: data í´ë”ì˜ CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìºì‹œ
# ------------------------------------------------------------
@st.cache_data(show_spinner=False)
def list_data_files():
    try:
        return [f for f in os.listdir(DATA_DIR) if f.lower().endswith(".csv")]
    except FileNotFoundError:
        return []

# ------------------------------------------------------------
# í¼ë¸”ë¦­ URL: cloudflared ì‹œì‘ í•¨ìˆ˜
# ------------------------------------------------------------
def start_cloudflared(port=8501):
    try:
        proc = subprocess.Popen(
            ["cloudflared", "tunnel", "--url", f"http://localhost:{port}"],
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True
        )
        st.session_state["_cfd_proc"] = proc  # ì¢…ë£Œìš© í•¸ë“¤ ì €ì¥
        with st.expander("cloudflared logs"):
            for _ in range(120):  # ìµœì´ˆ 120ë¼ì¸ ì •ë„ë§Œ ì½ì–´ í‘œì‹œ
                line = proc.stdout.readline()
                if not line:
                    break
                st.text(line.strip())
                if "trycloudflare.com" in line:
                    st.success(line.strip())  # í¼ë¸”ë¦­ URL í¬í•¨ ë¡œê·¸
                    break
    except FileNotFoundError:
        st.error("cloudflared ë°”ì´ë„ˆë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. `pip install cloudflared` ë˜ëŠ” ë°”ì´ë„ˆë¦¬ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

# ------------------------------------------------------------
# í¼ë¸”ë¦­ URL: ngrok ì‹œì‘ í•¨ìˆ˜
# ------------------------------------------------------------
def start_ngrok(port=8501, token: str | None = None):
    try:
        from pyngrok import ngrok, conf
    except Exception:
        st.error("pyngrokê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install pyngrok` í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return

    # ê¸°ì¡´ ngrok ì„¸ì…˜ ì •ë¦¬(ì¬ì‹¤í–‰ ì‹œ ì¶©ëŒ ë°©ì§€)
    try:
        ngrok.kill()
        time.sleep(1.0)
    except Exception:
        pass

    token = (token or os.environ.get("NGROK_AUTHTOKEN", "")).strip()
    if token:
        conf.get_default().auth_token = token
    else:
        st.warning("NGROK_AUTHTOKENì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì¸ì¦ ì—†ì´ ì—´ë©´ ì œí•œ/ì—ëŸ¬(4018) ê°€ëŠ¥.")

    for attempt in range(2):
        try:
            tunnel = ngrok.connect(addr=f"http://localhost:{port}", proto="http")
            url = tunnel.public_url
            st.session_state["_ngrok_tunnel"] = tunnel
            st.success(f"ğŸŒ Public URL: {url}")
            st.caption("ëŸ°íƒ€ì„/í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ë©´ í„°ë„ë„ ë‹«í™ë‹ˆë‹¤.")
            break
        except Exception as e:
            if attempt == 0:
                time.sleep(1.5)
            else:
                msg = str(e)
                if "4018" in msg:
                    st.error("ngrok ì¸ì¦ ì‹¤íŒ¨(4018). í† í°ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
                elif "already online" in msg or "334" in msg:
                    st.error("ë™ì¼ ì—”ë“œí¬ì¸íŠ¸ê°€ ì´ë¯¸ ì—´ë ¤ ìˆìŠµë‹ˆë‹¤. ì„¸ì…˜ ì¬ì‹œì‘ ë˜ëŠ” ê¸°ì¡´ í„°ë„ ì¢…ë£Œ í›„ ì¬ì‹œë„.")
                else:
                    st.error(f"ngrok ì—°ê²° ì‹¤íŒ¨: {e}")

# ------------------------------------------------------------
# ì•± íƒ€ì´í‹€/íƒ­ êµ¬ì„±
# ------------------------------------------------------------
st.title("í¸ì˜ì  ìˆ˜ìš”ì˜ˆì¸¡ & ë°œì£¼ ì¶”ì²œ â€” Pro Suite")
tabs = st.tabs(["â‘  ë°ì´í„°", "â‘¡ í•™ìŠµ/ëª¨ë¸", "â‘¢ ì˜ˆì¸¡Â·ë°œì£¼", "â‘£ ë¶„ì„(ê·¸ë˜í”„)", "â‘¤ ì§„ë‹¨/ë¡œê·¸"])

# ============================================================
# â‘  ë°ì´í„°: CSV ì—…ë¡œë“œ/ì„ íƒ + ìë™ ì»¬ëŸ¼ ë§¤í•‘ ì €ì¥ (ë©€í‹° CSV ì§€ì›)
# ============================================================
with tabs[0]:
    st.subheader("CSV ì—…ë¡œë“œ ë˜ëŠ” ì„ íƒ")
    cols_top = st.columns([2,1])
    with cols_top[0]:
        add_source = st.checkbox("íŒŒì¼ëª…(source) ì—´ ì¶”ê°€", value=True, help="ì—¬ëŸ¬ CSVë¥¼ í•©ì¹  ë•Œ ì›ë³¸ íŒŒì¼ëª…ì„ ë‚¨ê¹ë‹ˆë‹¤.")
    with cols_top[1]:
        st.caption("â€» ì—…ë¡œë“œ/ì„ íƒ í›„ ì•„ë˜ì—ì„œ ì»¬ëŸ¼ ë§¤í•‘ ì €ì¥")

    cols = st.columns(2)

    # --- ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ---
    with cols[0]:
        up_multi = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["csv"], accept_multiple_files=True, key="multi_up")
        if up_multi:
            dfs = []
            for f in up_multi:
                raw = f.read()
                df_i = read_csv_flexible(io.BytesIO(raw))
                if add_source:
                    df_i["source"] = f.name
                dfs.append(df_i)
                # data/ì— ì €ì¥
                save_path = os.path.join(DATA_DIR, f.name)
                try:
                    with open(save_path, "wb") as fp:
                        fp.write(raw)
                except Exception as e:
                    st.warning(f"íŒŒì¼ ì €ì¥ ê²½ê³ ({f.name}): {e}")
            try:
                list_data_files.clear()  # ìºì‹œ ë¬´íš¨í™”
            except Exception:
                pass
            df = pd.concat(dfs, axis=0, ignore_index=True, sort=True)
            st.session_state["df"] = df
            st.success(f"ì—…ë¡œë“œ/ê²°í•© ì™„ë£Œ: {df.shape} (íŒŒì¼ {len(dfs)}ê°œ)")
            st.dataframe(df.head(20), use_container_width=True)

    # --- data í´ë”ì—ì„œ ë‹¤ì¤‘ ì„ íƒ ---
    with cols[1]:
        files = list_data_files()
        picks = st.multiselect("data í´ë”ì—ì„œ ì„ íƒ(ì—¬ëŸ¬ ê°œ)", files)
        if st.button("ì„ íƒ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°", disabled=(len(picks)==0)):
            dfs = []
            for name in picks:
                path = os.path.join(DATA_DIR, name)
                df_i = read_csv_flexible(path)
                if add_source:
                    df_i["source"] = name
                dfs.append(df_i)
            df = pd.concat(dfs, axis=0, ignore_index=True, sort=True)
            st.session_state["df"] = df
            st.success(f"ë¶ˆëŸ¬ì˜¤ê¸°/ê²°í•© ì™„ë£Œ: {df.shape} (íŒŒì¼ {len(dfs)}ê°œ)")
            st.dataframe(df.head(20), use_container_width=True)

    # --- ìë™ ì»¬ëŸ¼ ë§¤í•‘ + ë³´ì • ---
    if "df" in st.session_state:
        st.divider()
        st.caption("ìë™ ì»¬ëŸ¼ ë§¤í•‘ â€” ì„ íƒ ì—†ì´ ìë™ ì ìš©ë©ë‹ˆë‹¤.")

        df = st.session_state["df"]

        # auto_map_columns ê²°ê³¼ ì‚¬ìš©
        auto = auto_map_columns(df)
        mapping = {
            "date": auto.get("date"),
            "target": auto.get("target"),
            "region": auto.get("region"),
            "brand": auto.get("brand"),
            "item": auto.get("item"),
        }
        st.session_state["mapping"] = mapping

        # â˜… data í´ë”ìš© ë³´ì •:
        #   seoul_gyeonggi_with_demand.csv / usan.csv / gungoguma.csv ëŠ”
        #   auto_map_columnsê°€ íƒ€ê¹ƒì„ 'ê°•ìˆ˜ëŸ‰'ìœ¼ë¡œ ì¡ëŠ” ì¼€ì´ìŠ¤ê°€ ìˆì–´ì„œ,
        #   'ì¼ì¼íŒë§¤ëŸ‰' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ê·¸ê±¸ targetìœ¼ë¡œ ê°•ì œ êµì²´
        if mapping.get("target") == "ê°•ìˆ˜ëŸ‰" and "ì¼ì¼íŒë§¤ëŸ‰" in df.columns:
            mapping["target"] = "ì¼ì¼íŒë§¤ëŸ‰"

        # í™•ì¸ìš©ìœ¼ë¡œë§Œ ì½ê¸° ì „ìš© í…Œì´ë¸” í‘œì‹œ
        mapping_view = pd.DataFrame(
            {
                "ì—­í• ": ["ë‚ ì§œ(date)", "ìˆ˜ìš”/íŒë§¤ëŸ‰(target)", "ì§€ì—­/ì í¬(region)", "ë¸Œëœë“œ(ì„ íƒ)", "ìƒí’ˆ/í’ˆëª©(ì„ íƒ)"],
                "ì»¬ëŸ¼": [
                    mapping.get("date"),
                    mapping.get("target"),
                    mapping.get("region"),
                    mapping.get("brand"),
                    mapping.get("item"),
                ],
            }
        )

        st.write("í˜„ì¬ ìë™ ë§¤í•‘ ê²°ê³¼:")
        st.dataframe(mapping_view, use_container_width=True)

# ============================================================
# â‘¡ í•™ìŠµ/ëª¨ë¸
# ============================================================
with tabs[1]:
    st.subheader("ëª¨ë¸ í•™ìŠµ")

    use_optuna = st.checkbox("Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‚¬ìš©", value=False)
    trials = st.slider("Optuna ì‹œë„ íšŸìˆ˜", 5, 60, 15, 5)

    if "df" not in st.session_state or "mapping" not in st.session_state:
        st.info("ë¨¼ì € â‘  íƒ­ì—ì„œ ë°ì´í„°ì™€ ì»¬ëŸ¼ ë§¤í•‘ì„ ì§€ì •í•˜ì„¸ìš”.")
    else:
        v = st.slider("ê²€ì¦ ë¹„ìœ¨(valid_ratio)", 0.05, 0.4, 0.2, 0.05)

        if st.button("í•™ìŠµ ì‹œì‘"):
            # âœ ì—¬ê¸°ì„œ ì˜ˆì™¸ê°€ ë‚˜ë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ë°©ì–´
            try:
                df, X, y, feat_names = make_matrix(
                    st.session_state["df"],
                    st.session_state["mapping"],
                )
            except Exception as e:
                st.error(f"í•™ìŠµìš© ë°ì´í„° êµ¬ì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            else:
                try:
                    best_model, lb = train_and_score(
                        X,
                        y,
                        valid_ratio=v,
                        use_optuna=use_optuna,
                        optuna_trials=trials,
                    )
                    save_artifacts(
                        [ARTI_DIR, MODELS_DIR],
                        best_model,
                        feat_names,
                        st.session_state["mapping"],
                        lb,
                    )
                except Exception as e:
                    st.error(f"ëª¨ë¸ í•™ìŠµ/ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                else:
                    st.session_state["leaderboard"] = lb
                    st.session_state["feat_names"] = feat_names
                    st.success("í•™ìŠµ ì™„ë£Œ")

        if "leaderboard" in st.session_state:
            st.dataframe(st.session_state["leaderboard"], use_container_width=True)

# ============================================================
# â‘¢ ì˜ˆì¸¡Â·ë°œì£¼: ë°˜ë³µ(AR) ì˜ˆì¸¡ + ì¬ê³  ê¸°ë°˜ ìë™ ë°œì£¼ ê³„ì‚°
# ============================================================
with tabs[2]:
    st.subheader("ì˜ˆì¸¡(ë°˜ë³µ AR) & ë°œì£¼ëŸ‰ ì¶”ì²œ")
    st.caption("í•™ìŠµëœ ëª¨ë¸ë¡œ ë¯¸ë˜ í”¼ì²˜ë¥¼ ìƒì„±í•˜ê³ , ì¬ê³ ë¥¼ ê³ ë ¤í•´ ìë™ìœ¼ë¡œ ë°œì£¼ ê¸°ê°„ê³¼ ìˆ˜ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")

    if "df" not in st.session_state or "mapping" not in st.session_state:
        st.info("ë¨¼ì € â‘  íƒ­ì—ì„œ ë°ì´í„°ì™€ ì»¬ëŸ¼ ë§¤í•‘ì„ ì§€ì •í•˜ê³  â‘¡ì—ì„œ í•™ìŠµì„ ì™„ë£Œí•˜ì„¸ìš”.")
    else:
        horizon_days = 14  # ê³ ì • ê¸°ê°„

        # ì •í™•ë„(ë³´ì • ê³„ìˆ˜)
        accuracy = st.slider(
            "ì •í™•ë„(ì˜ˆì¸¡ ë³´ì • ê³„ìˆ˜)",
            min_value=0.5,
            max_value=2.0,
            value=1.0,
            step=0.05,
        )

        # ==============================
        # ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
        # ==============================
        seg_cols = [
            c for c in [
                st.session_state["mapping"].get("region"),
                st.session_state["mapping"].get("brand"),
                st.session_state["mapping"].get("item"),
            ] if c
        ]
        seg_vals = {}
        if seg_cols:
            col_objs = st.columns(len(seg_cols))
            for i, ccol in enumerate(seg_cols):
                opts = ["<ì „ì²´>"] + sorted(
                    list(map(str, st.session_state["df"][ccol].dropna().astype(str).unique()))
                )
                seg_vals[ccol] = col_objs[i].selectbox(f"{ccol} ì„ íƒ", opts, index=0)

        # ==============================
        # ë°˜ë³µ ì˜ˆì¸¡ í•¨ìˆ˜
        # ==============================
        def iterative_forecast(df, mapping, model, feat_names, horizon, seg_vals):
            df = df.copy()
            dtc = mapping["date"]
            tgt = mapping["target"]

            if dtc not in df.columns or tgt not in df.columns:
                st.error(f"ì˜ˆì¸¡ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (date='{dtc}', target='{tgt}')")
                return pd.DataFrame(columns=[dtc, "ì˜ˆì¸¡ìˆ˜ëŸ‰"])

            df[dtc] = pd.to_datetime(df[dtc], errors="coerce")
            df = df.dropna(subset=[dtc]).sort_values(dtc)

            for k, v in seg_vals.items():
                if v and v != "<ì „ì²´>" and k in df.columns:
                    df = df[df[k].astype(str) == str(v)]

            if df.empty:
                st.error("ì„ íƒí•œ ì„¸ê·¸ë¨¼íŠ¸ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame(columns=[dtc, "ì˜ˆì¸¡ìˆ˜ëŸ‰"])

            if len(df) < 30:
                st.warning("í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ê°€ ì ì–´ ì˜ˆì¸¡ í’ˆì§ˆì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            last_date = df[dtc].max()

            hist = list(
                pd.to_numeric(df[tgt], errors="coerce")
                .fillna(0)
                .astype(float)
                .values
            )

            def build_row_features(current_date, hist_vals):
                if pd.isna(current_date):
                    current_date = df[dtc].max()

                year = current_date.year
                month = current_date.month
                day = current_date.day
                dow = current_date.weekday()
                is_weekend = 1 if dow >= 5 else 0

                try:
                    week = int(pd.Timestamp(current_date).isocalendar().week)
                except Exception:
                    week = 0

                def get_lag(k):
                    if len(hist_vals) >= k:
                        return float(hist_vals[-k])
                    return float(np.mean(hist_vals[-min(len(hist_vals), 7):])) if hist_vals else 0.0

                lag1 = get_lag(1)
                lag7 = get_lag(7)
                lag14 = get_lag(14)

                def rmean(w):
                    arr = np.array(hist_vals[-w:]) if len(hist_vals) >= 1 else np.array([0.0])
                    if len(arr) < max(2, w // 2):
                        arr = np.array(hist_vals[-max(2, w // 2):]) if len(hist_vals) else np.array([0.0])
                    return float(np.mean(arr))

                def rstd(w):
                    arr = np.array(hist_vals[-w:]) if len(hist_vals) >= 2 else np.array([0.0, 0.0])
                    return float(np.std(arr))

                feats = {
                    "year": year,
                    "month": month,
                    "day": day,
                    "dow": dow,
                    "week": week,
                    "is_weekend": is_weekend,
                    "lag1": lag1,
                    "lag7": lag7,
                    "lag14": lag14,
                    "rmean7": rmean(7),
                    "rmean14": rmean(14),
                    "rstd7": rstd(7),
                    "rstd14": rstd(14),
                }

                for fn in feat_names:
                    if fn not in feats:
                        feats[fn] = 0.0

                x = [feats.get(fn, 0.0) for fn in feat_names]
                return np.array(x, dtype=float)

            preds, dates = [], []
            cur = last_date
            for _ in range(int(horizon)):
                cur = cur + timedelta(days=1)
                x = build_row_features(cur, hist)
                val = float(model.predict([x])[0])
                preds.append(val)
                dates.append(cur)
                hist.append(val)

            return pd.DataFrame({dtc: dates, "ì˜ˆì¸¡ìˆ˜ëŸ‰": preds})

        # ==============================
        # ì¬ê³  ìë™ ì¸ì‹
        # ==============================
        def guess_inventory_onhand(df_seg: pd.DataFrame, mapping):
            candidates = [
                "ì¬ê³ ", "ì¬ê³ ìˆ˜", "ì¬ê³ ìˆ˜ëŸ‰",
                "í˜„ì¬ì¬ê³ ", "onhand", "on_hand",
                "stock", "inventory",
            ]
            inv_col = None
            for col in df_seg.columns:
                low = col.lower()
                if any(key in low for key in candidates):
                    inv_col = col
                    break
            if not inv_col:
                return None, None

            series = pd.to_numeric(df_seg[inv_col], errors="coerce").dropna()
            if series.empty:
                return None, None

            return inv_col, float(series.iloc[-1])

        # ==============================
        # ê°€ê²© ìë™ ì¸ì‹
        # ==============================
        def guess_price_column(df_seg):
            keys = ["price", "ê°€ê²©", "ë‹¨ê°€", "íŒë§¤ê°€", "amount", "ê¸ˆì•¡"]
            for col in df_seg.columns:
                low = col.lower()
                if any(k in low for k in keys):
                    return col
            return None

        # ==============================
        # ëª¨ë¸ ë¡œë“œ
        # ==============================
        pkl_path = os.path.join(MODELS_DIR, "best_model.pkl")
        if os.path.exists(pkl_path):
            try:
                with open(pkl_path, "rb") as f:
                    payload = pickle.load(f)
                model = payload["model"]
                feat_names = payload["feature_names"]
                mapping = payload["mapping"]
            except Exception as e:
                st.error(f"ì €ì¥ëœ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                dtc = mapping["date"]

                # ======================================
                # 1) ì˜ˆì¸¡ ìˆ˜í–‰
                # ======================================
                fc_df = iterative_forecast(
                    st.session_state["df"],
                    mapping,
                    model,
                    feat_names,
                    horizon_days,
                    seg_vals,
                )
                if fc_df.empty:
                    st.stop()

                # ======================================
                # 2) ê°€ê²© ìë™ ì¸ì‹ + ê¸ˆì•¡ì˜ˆì¸¡
                # ======================================
                df_seg_price = st.session_state["df"].copy()
                for k, v in seg_vals.items():
                    if v and v != "<ì „ì²´>" and k in df_seg_price.columns:
                        df_seg_price = df_seg_price[df_seg_price[k].astype(str) == str(v)]
                df_seg_price = df_seg_price.sort_values(dtc)

                price_col = guess_price_column(df_seg_price)

                if price_col:
                    price_val = float(
                        pd.to_numeric(df_seg_price[price_col], errors="coerce").dropna().iloc[-1]
                    )
                    st.info(f"CSV '{price_col}' ì»¬ëŸ¼ì—ì„œ ê°€ê²© {price_val:,.0f}ì› ìë™ ì¸ì‹.")
                else:
                    price_val = st.number_input(
                        "ê°€ê²©(ì›) â€“ CSVì—ì„œ ê°€ê²© ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ ì§ì ‘ ì…ë ¥",
                        min_value=0,
                        max_value=100000000,
                        value=0,
                    )

                # **ìˆ˜ëŸ‰ ì´í•©**
                total_qty_demand = float(fc_df["ì˜ˆì¸¡ìˆ˜ëŸ‰"].sum())

                # **ê¸ˆì•¡ ì´í•©**
                fc_df["ê¸ˆì•¡ì˜ˆì¸¡"] = (fc_df["ì˜ˆì¸¡ìˆ˜ëŸ‰"] * price_val * float(accuracy)).clip(lower=0.0)
                total_amt_demand = float(fc_df["ê¸ˆì•¡ì˜ˆì¸¡"].sum())

                # ======================================
                # 3) ì¬ê³  ìë™ ì¸ì‹
                # ======================================
                df_seg = st.session_state["df"].copy()
                df_seg[dtc] = pd.to_datetime(df_seg[dtc], errors="coerce")
                for k, v in seg_vals.items():
                    if v and v != "<ì „ì²´>" and k in df_seg.columns:
                        df_seg = df_seg[df_seg[k].astype(str) == str(v)]
                df_seg = df_seg.sort_values(dtc)

                inv_col, onhand_auto = guess_inventory_onhand(df_seg, mapping)
                if onhand_auto is None:
                    onhand = st.number_input(
                        "í˜„ì¬ ì¬ê³ (ì§ì ‘ ì…ë ¥)",
                        min_value=0,
                        max_value=100000,
                        value=0,
                    )
                else:
                    onhand = onhand_auto
                    st.info(f"ì¬ê³  '{inv_col}' ìë™ ì¸ì‹ â†’ {onhand:,.0f}ê°œ")

                # ======================================
                # 4) ë°œì£¼ëŸ‰/ì†Œì§„ì¼ ê³„ì‚° (ìˆ˜ëŸ‰ ê¸°ì¤€)
                # ======================================
                avg_daily_qty = total_qty_demand / horizon_days if horizon_days > 0 else 0.0
                days_to_out = (onhand / avg_daily_qty) if avg_daily_qty > 0 else float("inf")
                rec_qty = max(0.0, total_qty_demand - onhand)

                c1, c2, c3 = st.columns(3)
                c1.metric("ì˜ˆì¸¡ ê¸°ê°„(ì¼)", f"{horizon_days}")
                c2.metric("ì¬ê³  ì†Œì§„ ì˜ˆìƒì¼ìˆ˜", "âˆ" if np.isinf(days_to_out) else f"{days_to_out:,.1f}")
                c3.metric("2ì£¼ ì´ ì˜ˆìƒ ë§¤ì¶œ", f"{total_amt_demand:,.0f}ì›")

                # ======================================
                # 5) í‘œ ì¶œë ¥
                # ======================================
                st.dataframe(fc_df.set_index(dtc), use_container_width=True)
                st.caption("â€» ì˜ˆì¸¡ìˆ˜ëŸ‰ Ã— ê°€ê²© Ã— ì •í™•ë„ ë³´ì • = ê¸ˆì•¡ì˜ˆì¸¡")

        else:
            st.warning("best_model.pkl ì´ ì—†ìŠµë‹ˆë‹¤. â‘¡ íƒ­ì—ì„œ í•™ìŠµì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”.")

# ============================================================
# â‘£ ë¶„ì„(ê·¸ë˜í”„):
#   - ìš°ì‚°: í•œ ë‹¬ ê°•ìˆ˜ëŸ‰ vs ìš°ì‚° íŒë§¤ëŸ‰ (ì‚°ì ë„ + íšŒê·€ì„  + ì¼ë³„ ì„ í˜• ê·¸ë˜í”„)
#   - êµ°ê³ êµ¬ë§ˆ: í•œ ë‹¬ ê¸°ì˜¨ vs êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰ (ì‚°ì ë„ + íšŒê·€ì„  + ì¼ë³„ ì„ í˜• ê·¸ë˜í”„)
#   - ì „ì²´: ìš°ì‚°Â·êµ°ê³ êµ¬ë§ˆ ì œì™¸ ì¼ë³„ íŒë§¤ëŸ‰ ì„ í˜• ê·¸ë˜í”„
# ============================================================
with tabs[3]:
    st.subheader("ë¶„ì„(ê·¸ë˜í”„) â€” í•œ ë‹¬ ë‹¨ìœ„ ìƒê´€ ë¶„ì„")

    if "df" not in st.session_state or "mapping" not in st.session_state or not st.session_state["mapping"].get("date"):
        st.info("ë¨¼ì € â‘  íƒ­ì—ì„œ ë°ì´í„°ì™€ ì»¬ëŸ¼ ë§¤í•‘(íŠ¹íˆ 'ë‚ ì§œ'ì™€ 'íƒ€ê¹ƒ')ì„ ì§€ì •í•˜ì„¸ìš”.")
    else:
        mapping = st.session_state["mapping"]
        date_col = mapping["date"]
        target_col = mapping.get("target")

        def guess(colnames, cands):
            low = [str(c).lower() for c in colnames]
            for key in cands:
                key_low = str(key).lower()
                for i, l in enumerate(low):
                    if key_low in l:
                        return colnames[i]
            return None

        # ê³µí†µ: ì—°-ì›” ì„ íƒìš© ì˜µì…˜ ë§Œë“œëŠ” í•¨ìˆ˜
        def build_year_month_options(df, date_col):
            df = df.copy()
            df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
            df = df.dropna(subset=[date_col])
            if df.empty:
                return df, []
            df["year_month"] = df[date_col].dt.to_period("M")
            ym_unique = sorted(df["year_month"].unique())
            ym_labels = [str(p) for p in ym_unique]  # '2024-10' ê°™ì€ í˜•ì‹
            return df, list(zip(ym_labels, ym_unique))

        tab_u, tab_g, tab_all = st.tabs([
            "â˜” ìš°ì‚°: í•œ ë‹¬ ê°•ìˆ˜ëŸ‰ vs íŒë§¤ëŸ‰",
            "ğŸ  êµ°ê³ êµ¬ë§ˆ: í•œ ë‹¬ ê¸°ì˜¨ vs íŒë§¤ëŸ‰",
            "ğŸ“ˆ ì „ì²´: ìš°ì‚°Â·êµ°ê³ êµ¬ë§ˆ ì œì™¸ ì¼ë³„ íŒë§¤ëŸ‰(ì„ í˜•)"
        ])

        # ------------------------------
        # 1) ìš°ì‚°: ì„ íƒí•œ í•œ ë‹¬ì˜ ê°•ìˆ˜ëŸ‰ â†” ìš°ì‚° íŒë§¤ëŸ‰
        # ------------------------------
        with tab_u:
            st.caption("ìš°ì‚° íŒë§¤ëŸ‰ê³¼ ê°•ìˆ˜ëŸ‰ì˜ ê´€ê³„ë¥¼ 'í•œ ë‹¬' ë‹¨ìœ„ë¡œ ë´…ë‹ˆë‹¤.")

            up_u = st.file_uploader("ìš°ì‚°/ë‚ ì”¨ ë°ì´í„° CSV (ì„ íƒ)", type=["csv"], key="umbrella_month_up")
            if up_u is not None:
                df_u_raw = read_csv_flexible(io.BytesIO(up_u.read()))
            else:
                df_u_raw = st.session_state["df"].copy()

            if date_col not in df_u_raw.columns:
                st.warning(f"ë‚ ì§œ ì»¬ëŸ¼ '{date_col}' ì„(ë¥¼) ë°ì´í„°ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                # itemì—ì„œ ìš°ì‚°ë§Œ í•„í„° (ìˆìœ¼ë©´)
                item_col = mapping.get("item")
                if item_col and item_col in df_u_raw.columns:
                    mask = df_u_raw[item_col].astype(str).str.contains("ìš°ì‚°|umbrella", case=False, na=False)
                    if mask.any():
                        df_u_raw = df_u_raw[mask]

                cols_all = list(df_u_raw.columns)

                # íŒë§¤ëŸ‰ ì»¬ëŸ¼: ë§¤í•‘ target ìš°ì„ , ì—†ìœ¼ë©´ ì¶”ì •
                sales_col = target_col if target_col in cols_all else guess(
                    cols_all,
                    ["umbrella", "ìš°ì‚°", "ì¼ì¼íŒë§¤ëŸ‰", "íŒë§¤ëŸ‰", "sales", "qty", "quantity", "target"],
                )

                # ê°•ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì¶”ì •
                rain_col = guess(
                    cols_all,
                    ["rain", "precip", "precipitation", "ê°•ìˆ˜", "ê°•ìˆ˜ëŸ‰", "ì¼ê°•ìˆ˜ëŸ‰", "ê°•ìš°", "ê°•ìš°ëŸ‰"],
                )

                if not sales_col or not rain_col:
                    st.warning(
                        "ìš°ì‚° íŒë§¤ëŸ‰ ë˜ëŠ” ê°•ìˆ˜ëŸ‰ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
                        "íŒë§¤ëŸ‰: 'ìš°ì‚°/umbrella/íŒë§¤ëŸ‰/sales', ê°•ìˆ˜ëŸ‰: 'ê°•ìˆ˜ëŸ‰/rain' ë“±ì˜ ì´ë¦„ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”."
                    )
                else:
                    # ë‚ ì§œ/ìˆ«ì í˜•ì‹ ì •ë¦¬ + ì—°-ì›” ì˜µì…˜ ìƒì„±
                    df_u_raw[sales_col] = pd.to_numeric(df_u_raw[sales_col], errors="coerce")
                    df_u_raw[rain_col] = pd.to_numeric(df_u_raw[rain_col], errors="coerce")

                    df_u_raw, ym_options = build_year_month_options(df_u_raw, date_col)

                    if not ym_options:
                        st.info("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ì—°-ì›” ì„ íƒ (YYYY-MM í˜•ì‹ë§Œ ë³´ì—¬ì¤Œ)
                        labels = [lab for lab, _ in ym_options]
                        default_idx = len(labels) - 1  # ê¸°ë³¸ê°’: ê°€ì¥ ìµœê·¼ ì›”
                        sel_label = st.selectbox("ë¶„ì„í•  ì—°ì›”(YYYY-MM)", labels, index=default_idx, key="ym_umbrella")
                        sel_period = dict(ym_options)[sel_label]

                        # ì„ íƒí•œ í•œ ë‹¬ë§Œ í•„í„°
                        df_month = df_u_raw[df_u_raw["year_month"] == sel_period].copy()
                        if df_month.empty:
                            st.info(f"{sel_label} ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ì¼ ë‹¨ìœ„ ì§‘ê³„
                            df_month["date_only"] = df_month[date_col].dt.date
                            daily = (
                                df_month.groupby("date_only", as_index=False)
                                .agg({sales_col: "sum", rain_col: "mean"})
                                .dropna(subset=[sales_col, rain_col])
                            )
                            daily = daily.rename(
                                columns={"date_only": "date", sales_col: "sales", rain_col: "rain"}
                            )

                            if daily.empty:
                                st.info("í•´ë‹¹ ì—°ì›”ì—ì„œ ì¼ë³„ë¡œ ì§‘ê³„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.markdown(f"**{sel_label} í•œ ë‹¬ ê¸°ì¤€ Â· ê°•ìˆ˜ëŸ‰ì— ë”°ë¥¸ ìš°ì‚° íŒë§¤ëŸ‰**")

                                base = alt.Chart(daily).encode(
                                    x=alt.X("rain:Q", title="ì¼ ê°•ìˆ˜ëŸ‰"),
                                    y=alt.Y("sales:Q", title="ì¼ ìš°ì‚° íŒë§¤ëŸ‰"),
                                )

                                # ë¶‰ì€ìƒ‰ ì‚°ì ë„ + ì„ í˜• íšŒê·€ì„ 
                                points = base.mark_circle(size=70, color="#d62728").encode(
                                    tooltip=[
                                        alt.Tooltip("date:T", title="ë‚ ì§œ"),
                                        alt.Tooltip("rain:Q", title="ê°•ìˆ˜ëŸ‰"),
                                        alt.Tooltip("sales:Q", title="ìš°ì‚° íŒë§¤ëŸ‰"),
                                    ]
                                )
                                reg_line = base.transform_regression("rain", "sales").mark_line(color="#b22222")

                                st.altair_chart((points + reg_line).interactive(), use_container_width=True)

                                # â˜… ì¶”ê°€: ì¼ë³„ ìš°ì‚° íŒë§¤ëŸ‰ ì„ í˜• ê·¸ë˜í”„
                                st.markdown("**ì¼ë³„ ìš°ì‚° íŒë§¤ëŸ‰ ì¶”ì„¸(ì„ í˜• ê·¸ë˜í”„)**")
                                line_umbrella = (
                                    alt.Chart(daily)
                                    .mark_line()
                                    .encode(
                                        x=alt.X("date:T", title="ë‚ ì§œ"),
                                        y=alt.Y("sales:Q", title="ì¼ ìš°ì‚° íŒë§¤ëŸ‰"),
                                        tooltip=[
                                            alt.Tooltip("date:T", title="ë‚ ì§œ"),
                                            alt.Tooltip("sales:Q", title="ìš°ì‚° íŒë§¤ëŸ‰"),
                                            alt.Tooltip("rain:Q", title="ê°•ìˆ˜ëŸ‰"),
                                        ],
                                    )
                                )
                                st.altair_chart(line_umbrella.interactive(), use_container_width=True)

                                # ì°¸ê³ ìš© í…Œì´ë¸”
                                st.dataframe(daily, use_container_width=True)

        # ------------------------------
        # 2) êµ°ê³ êµ¬ë§ˆ: ì„ íƒí•œ í•œ ë‹¬ì˜ ê¸°ì˜¨ â†” êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰
        # ------------------------------
        with tab_g:
            st.caption("êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰ê³¼ ê¸°ì˜¨(ì¶”ìœ„)ì˜ ê´€ê³„ë¥¼ 'í•œ ë‹¬' ë‹¨ìœ„ë¡œ ë´…ë‹ˆë‹¤.")

            up_g = st.file_uploader("êµ°ê³ êµ¬ë§ˆ/ë‚ ì”¨ ë°ì´í„° CSV (ì„ íƒ)", type=["csv"], key="goguma_month_up")
            if up_g is not None:
                df_g_raw = read_csv_flexible(io.BytesIO(up_g.read()))
            else:
                df_g_raw = st.session_state["df"].copy()

            if date_col not in df_g_raw.columns:
                st.warning(f"ë‚ ì§œ ì»¬ëŸ¼ '{date_col}' ì„(ë¥¼) ë°ì´í„°ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                # itemì—ì„œ êµ°ê³ êµ¬ë§ˆë§Œ í•„í„° (ìˆìœ¼ë©´)
                item_col_g = mapping.get("item")
                if item_col_g and item_col_g in df_g_raw.columns:
                    mask_g = df_g_raw[item_col_g].astype(str).str.contains(
                        "ê³ êµ¬ë§ˆ|êµ°ê³ êµ¬ë§ˆ|sweet|goguma", case=False, na=False
                    )
                    if mask_g.any():
                        df_g_raw = df_g_raw[mask_g]

                cols_all_g = list(df_g_raw.columns)

                goguma_col = target_col if target_col in cols_all_g else guess(
                    cols_all_g,
                    ["ê³ êµ¬ë§ˆ", "êµ°ê³ êµ¬ë§ˆ", "sweetpotato", "goguma", "íŒë§¤ëŸ‰", "sales", "qty", "quantity", "target"],
                )
                temp_col = guess(
                    cols_all_g,
                    ["ì˜¨ë„", "tmin", "temp_min", "min_temp", "ìµœì €", "ìµœì €ê¸°ì˜¨", "ì¼ìµœì €ê¸°ì˜¨", "temperature", "temp"],
                )

                if not goguma_col or not temp_col:
                    st.warning(
                        "êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰ ë˜ëŠ” ê¸°ì˜¨ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
                        "íŒë§¤ëŸ‰: 'êµ°ê³ êµ¬ë§ˆ/ê³ êµ¬ë§ˆ/sales/target', ê¸°ì˜¨: 'tmin/ìµœì €ê¸°ì˜¨/temperature' ë“±ì˜ ì´ë¦„ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”."
                    )
                else:
                    df_g_raw[goguma_col] = pd.to_numeric(df_g_raw[goguma_col], errors="coerce")
                    df_g_raw[temp_col] = pd.to_numeric(df_g_raw[temp_col], errors="coerce")

                    df_g_raw, ym_options_g = build_year_month_options(df_g_raw, date_col)

                    if not ym_options_g:
                        st.info("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        labels_g = [lab for lab, _ in ym_options_g]
                        default_idx_g = len(labels_g) - 1
                        sel_label_g = st.selectbox("ë¶„ì„í•  ì—°ì›”(YYYY-MM)", labels_g, index=default_idx_g, key="ym_goguma")
                        sel_period_g = dict(ym_options_g)[sel_label_g]

                        df_month_g = df_g_raw[df_g_raw["year_month"] == sel_period_g].copy()
                        if df_month_g.empty:
                            st.info(f"{sel_label_g} ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            df_month_g["date_only"] = df_month_g[date_col].dt.date
                            daily_g = (
                                df_month_g.groupby("date_only", as_index=False)
                                .agg({goguma_col: "sum", temp_col: "mean"})
                                .dropna(subset=[goguma_col, temp_col])
                            )
                            daily_g = daily_g.rename(
                                columns={"date_only": "date", goguma_col: "sales", temp_col: "temp"}
                            )

                            if daily_g.empty:
                                st.info("í•´ë‹¹ ì—°ì›”ì—ì„œ ì¼ë³„ë¡œ ì§‘ê³„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.markdown(f"**{sel_label_g} í•œ ë‹¬ ê¸°ì¤€ Â· ê¸°ì˜¨ì— ë”°ë¥¸ êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰**")

                                base_g = alt.Chart(daily_g).encode(
                                    x=alt.X("temp:Q", title="ì¼ í‰ê·  ê¸°ì˜¨"),
                                    y=alt.Y("sales:Q", title="ì¼ êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰"),
                                )

                                points_g = base_g.mark_circle(size=70, color="#ff7f0e").encode(
                                    tooltip=[
                                        alt.Tooltip("date:T", title="ë‚ ì§œ"),
                                        alt.Tooltip("temp:Q", title="ê¸°ì˜¨"),
                                        alt.Tooltip("sales:Q", title="êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰"),
                                    ]
                                )
                                reg_g = base_g.transform_regression("temp", "sales").mark_line(color="#d35400")

                                st.altair_chart((points_g + reg_g).interactive(), use_container_width=True)

                                # â˜… ì¶”ê°€: ì¼ë³„ êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰ ì„ í˜• ê·¸ë˜í”„
                                st.markdown("**ì¼ë³„ êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰ ì¶”ì„¸(ì„ í˜• ê·¸ë˜í”„)**")
                                line_goguma = (
                                    alt.Chart(daily_g)
                                    .mark_line()
                                    .encode(
                                        x=alt.X("date:T", title="ë‚ ì§œ"),
                                        y=alt.Y("sales:Q", title="ì¼ êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰"),
                                        tooltip=[
                                            alt.Tooltip("date:T", title="ë‚ ì§œ"),
                                            alt.Tooltip("temp:Q", title="ê¸°ì˜¨"),
                                            alt.Tooltip("sales:Q", title="êµ°ê³ êµ¬ë§ˆ íŒë§¤ëŸ‰"),
                                        ],
                                    )
                                )
                                st.altair_chart(line_goguma.interactive(), use_container_width=True)

                                st.dataframe(daily_g, use_container_width=True)

        # ------------------------------
        # 3) ì „ì²´: ìš°ì‚°Â·êµ°ê³ êµ¬ë§ˆ ì œì™¸ ì „ì²´ ìƒí’ˆ ì¼ë³„ íŒë§¤ëŸ‰ ì„ í˜• ê·¸ë˜í”„
        # ------------------------------
        with tab_all:
            st.caption("ìš°ì‚°Â·êµ°ê³ êµ¬ë§ˆë¥¼ ì œì™¸í•œ ëª¨ë“  ìƒí’ˆì˜ ì¼ë³„ íŒë§¤ëŸ‰ ì¶”ì„¸ë¥¼ í•œ ë²ˆì— ë´…ë‹ˆë‹¤.")

            df_all = st.session_state["df"].copy()

            if date_col not in df_all.columns or not target_col or target_col not in df_all.columns:
                st.warning(f"ë‚ ì§œ('{date_col}') ë˜ëŠ” íƒ€ê¹ƒ('{target_col}') ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # item ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ìš°ì‚°/êµ°ê³ êµ¬ë§ˆ ê´€ë ¨ ìƒí’ˆ ì œì™¸
                item_col_all = mapping.get("item")
                if item_col_all and item_col_all in df_all.columns:
                    ex_mask = df_all[item_col_all].astype(str).str.contains(
                        "ìš°ì‚°|umbrella|ê³ êµ¬ë§ˆ|êµ°ê³ êµ¬ë§ˆ|sweet|goguma", case=False, na=False
                    )
                    df_all = df_all[~ex_mask]

                df_all[target_col] = pd.to_numeric(df_all[target_col], errors="coerce")

                df_all, ym_options_all = build_year_month_options(df_all, date_col)

                if not ym_options_all:
                    st.info("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    labels_all = [lab for lab, _ in ym_options_all]
                    default_idx_all = len(labels_all) - 1
                    sel_label_all = st.selectbox(
                        "ë¶„ì„í•  ì—°ì›”(YYYY-MM)",
                        labels_all,
                        index=default_idx_all,
                        key="ym_all",
                    )
                    sel_period_all = dict(ym_options_all)[sel_label_all]

                    df_month_all = df_all[df_all["year_month"] == sel_period_all].copy()
                    if df_month_all.empty:
                        st.info(f"{sel_label_all} ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        df_month_all["date_only"] = df_month_all[date_col].dt.date
                        daily_all = (
                            df_month_all.groupby("date_only", as_index=False)
                            .agg({target_col: "sum"})
                            .dropna(subset=[target_col])
                        )
                        daily_all = daily_all.rename(
                            columns={"date_only": "date", target_col: "sales"}
                        )

                        if daily_all.empty:
                            st.info("í•´ë‹¹ ì—°ì›”ì—ì„œ ì¼ë³„ë¡œ ì§‘ê³„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.markdown(f"**{sel_label_all} í•œ ë‹¬ ê¸°ì¤€ Â· ìš°ì‚°Â·êµ°ê³ êµ¬ë§ˆ ì œì™¸ ì „ì²´ ìƒí’ˆ ì¼ë³„ íŒë§¤ëŸ‰(ì„ í˜•)**")

                            line_all = (
                                alt.Chart(daily_all)
                                .mark_line()
                                .encode(
                                    x=alt.X("date:T", title="ë‚ ì§œ"),
                                    y=alt.Y("sales:Q", title="ì¼ íŒë§¤ëŸ‰(ì „ì²´ ìƒí’ˆ í•©ê³„)"),
                                    tooltip=[
                                        alt.Tooltip("date:T", title="ë‚ ì§œ"),
                                        alt.Tooltip("sales:Q", title="ì¼ íŒë§¤ëŸ‰ í•©ê³„"),
                                    ],
                                )
                            )
                            st.altair_chart(line_all.interactive(), use_container_width=True)
                            st.dataframe(daily_all, use_container_width=True)

# ============================================================
# â‘¤ ì§„ë‹¨/ë¡œê·¸: ê²½ë¡œ/íŒŒì¼ í™•ì¸ + í¼ë¸”ë¦­ URL ì—´ê¸°/ë‹«ê¸°
# ============================================================
with tabs[4]:
    st.subheader("ê²½ë¡œ/íŒŒì¼ ìƒíƒœ")

    cols = st.columns(2)
    with cols[0]:
        st.write("**data**", DATA_DIR)
        st.write(os.listdir(DATA_DIR) if os.path.exists(DATA_DIR) else [])
        st.write("**artifacts**", ARTI_DIR)
        st.write(os.listdir(ARTI_DIR) if os.path.exists(ARTI_DIR) else [])
    with cols[1]:
        st.write("**models**", MODELS_DIR)
        st.write(os.listdir(MODELS_DIR) if os.path.exists(MODELS_DIR) else [])

    st.caption("í•„ìš” ì‹œ í¼ë¸”ë¦­ URLì„ ì—´ì–´ ì™¸ë¶€ì—ì„œ ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    mode = st.radio("í¼ë¸”ë¦­ URL í„°ë„ëŸ¬", ["ngrok", "cloudflared"], horizontal=True, index=0)

    ngk = None
    if mode == "ngrok":
        ngk = st.text_input(
            "NGROK_AUTHTOKEN",
            value=os.environ.get("NGROK_AUTHTOKEN", ""),
            type="password",
            help="í™˜ê²½ë³€ìˆ˜ì— ë„£ì–´ë‘ë©´ ë‹¤ìŒë¶€í„° ìë™ ì¸ì‹í•©ë‹ˆë‹¤.",
        )

    c_open, c_close = st.columns(2)
    if c_open.button("í¼ë¸”ë¦­ URL ì—´ê¸°", use_container_width=True):
        if mode == "ngrok":
            if ngk:
                os.environ["NGROK_AUTHTOKEN"] = ngk
            start_ngrok()
        else:
            start_cloudflared()

    if c_close.button("í¼ë¸”ë¦­ URL ë‹«ê¸°", use_container_width=True):
        if mode == "ngrok":
            try:
                from pyngrok import ngrok
                ngrok.kill()
                st.info("ngrok í„°ë„ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"ngrok ì¢…ë£Œ ì¤‘ ê²½ê³ : {e}")
        else:
            proc = st.session_state.get("_cfd_proc")
            if proc:
                proc.terminate()
                st.info("cloudflared í„°ë„ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
            else:
                st.info("cloudflared í™œì„± í”„ë¡œì„¸ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
